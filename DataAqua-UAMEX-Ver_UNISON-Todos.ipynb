{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7374daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 1: Imports y configuración ===\n",
    "from pathlib import Path\n",
    "import os, re, warnings\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc7a1bc-8efe-4815-a197-828e0bf3b2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Ciclo</th>\n",
       "      <th>Ruta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2010-2011</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2011-2012</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2012-2013</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2013-2014</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cajeme</td>\n",
       "      <td>2014-2015</td>\n",
       "      <td>/lustre/home/mvalenzuela/Workspace/DataAqua-da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Region      Ciclo                                               Ruta\n",
       "0  Cajeme  2010-2011  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "1  Cajeme  2011-2012  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "2  Cajeme  2012-2013  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "3  Cajeme  2013-2014  /lustre/home/mvalenzuela/Workspace/DataAqua-da...\n",
       "4  Cajeme  2014-2015  /lustre/home/mvalenzuela/Workspace/DataAqua-da..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Celda 2: Rutas, mapeo y utilidades ===\n",
    "\n",
    "# Detectar base según entorno: cluster o local\n",
    "RUTA_BASE = Path(\n",
    "    os.getenv(\"DATAAQUA_BASE\", \"/lustre/home/mvalenzuela/Workspace/DataAqua-dashboard\")\n",
    ")\n",
    "if not RUTA_BASE.exists():\n",
    "    # fallback si no está en el cluster, usar la carpeta actual (tu PC local)\n",
    "    RUTA_BASE = Path(\".\").resolve()\n",
    "\n",
    "# Carpeta de datos relativa al repo\n",
    "RUTA_SALIDA_UNISON = RUTA_BASE / \"data\" / \"Salidas_ETo12_con_uac_y_hh\" / \"Periodo de Cultivo ETo\"\n",
    "\n",
    "# Carpeta de salida de reportes PDF\n",
    "RUTA_REPORTES = RUTA_BASE / \"reports\" / \"modelos\"\n",
    "RUTA_REPORTES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mapeo de columnas (igual al del dashboard, añadiendo UAC/HH)\n",
    "MAP_UNISON = {\n",
    "    \"Año_ (YEAR)\": \"Year\", \"AÃ±o_ (YEAR)\": \"Year\",\n",
    "    \"Día (DOY)\": \"DOY\",   \"DÃ­a (DOY)\": \"DOY\",\n",
    "    \"Tmax (T2M_MAX)\": \"Tmax\", \"Tmin (T2M_MIN)\": \"Tmin\",\n",
    "    \"HR (RH2M)\": \"HR\", \"Ux (WS2M)\": \"Ux\",\n",
    "    \"Rs (ALLSKY_SFC_SW_DWN)\": \"Rs\",\n",
    "    \"Rl_ (ALLSKY_SFC_LW_DWN)\": \"Rl\",\n",
    "    \"Ptot_ (PRECTOTCORR)\": \"Ptot\",\n",
    "    \"Pef_\": \"Pef\", \"Tmean_\": \"Tmean\", \"es_\": \"es\", \"ea_\": \"ea\",\n",
    "    \"delta_\": \"delta\", \"P_\": \"P\", \"gamma_\": \"gamma\",\n",
    "    \"Rns_\": \"Rns\", \"Rnl_\": \"Rnl\", \"Rn_\": \"Rn\", \"Rso_\": \"Rso\",\n",
    "    \"Kc_\": \"Kc\", \"decada_\": \"decada\",\n",
    "    \"ET0\": \"ET0\", \"ETc\": \"ETc\", \"ETverde\": \"ETverde\", \"ETazul\": \"ETazul\",\n",
    "    \"Year\": \"Year\", \"DOY\": \"DOY\", \"Dia\": \"Dia\",\n",
    "    \"UACverde_m3_ha\": \"UACverde_m3_ha\",\n",
    "    \"UACazul_m3_ha\": \"UACazul_m3_ha\",\n",
    "    \"HHverde_m3_ton\": \"HHverde_m3_ton\",\n",
    "    \"HHazul_m3_ton\": \"HHazul_m3_ton\",\n",
    "}\n",
    "\n",
    "COLUMNAS_NUM = [\n",
    "    \"Year\",\"DOY\",\"ET0\",\"ETc\",\"ETverde\",\"ETazul\",\"Pef\",\"decada\",\n",
    "    \"Rns\",\"Rnl\",\"Rs\",\"Tmean\",\"HR\",\"Ux\",\"Kc\",\"Tmax\",\"Tmin\",\n",
    "    \"UACverde_m3_ha\",\"UACazul_m3_ha\",\"HHverde_m3_ton\",\"HHazul_m3_ton\"\n",
    "]\n",
    "\n",
    "def _year_doy_to_date(y, doy):\n",
    "    try:\n",
    "        base = datetime(int(y), 1, 1)\n",
    "        return base + timedelta(days=int(doy) - 1)\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def leer_y_normalizar(path: str) -> pd.DataFrame:\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    last_err = None\n",
    "    for enc in (\"utf-8\",\"latin-1\"):\n",
    "        try:\n",
    "            df = pd.read_csv(p, encoding=enc)\n",
    "            last_err = None\n",
    "            break\n",
    "        except UnicodeDecodeError as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    if last_err is not None:\n",
    "        df = pd.read_csv(p)\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    df = df.rename(columns=lambda c: MAP_UNISON.get(c, c))\n",
    "\n",
    "    # si no existe 'Día' y tenemos DOY, crea 'Día' para compatibilidad con la libreta\n",
    "    if \"Día\" not in df.columns and \"DOY\" in df.columns:\n",
    "        df[\"Día\"] = pd.to_numeric(df[\"DOY\"], errors=\"coerce\")\n",
    "\n",
    "    for c in set(COLUMNAS_NUM).intersection(df.columns):\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    # Fecha y Día de ciclo (opcional)\n",
    "    if {\"Year\",\"DOY\"}.issubset(df.columns):\n",
    "        fechas = [_year_doy_to_date(y,d) for y,d in zip(df[\"Year\"], df[\"DOY\"])]\n",
    "        df[\"Fecha\"] = pd.to_datetime(fechas)\n",
    "        if df[\"Fecha\"].notna().any():\n",
    "            f0 = df[\"Fecha\"].dropna().iloc[0]\n",
    "            df[\"Dia_ciclo\"] = (df[\"Fecha\"] - f0).dt.days.astype(\"Int64\")\n",
    "        else:\n",
    "            df[\"Dia_ciclo\"] = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "    else:\n",
    "        df[\"Fecha\"] = pd.NaT\n",
    "        df[\"Dia_ciclo\"] = pd.Series(pd.NA, index=df.index, dtype=\"Int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def parse_unison_filename(filename: str):\n",
    "    m = re.match(r\"([A-Za-zÁÉÍÓÚáéíóúñÑ\\s]+)-FAO56-(\\d{4})(?:-(\\d{4}))?-SALIDA\\.csv$\", filename, re.I)\n",
    "    if not m: return None, None\n",
    "    reg, y1, y2 = m.groups()\n",
    "    if reg == \"VillaAllende\": reg = \"Villa de Allende\"\n",
    "    if reg == \"Etchhojoa\":    reg = \"Etchojoa\"\n",
    "    ciclo = y1 if not y2 else f\"{y1}-{y2}\"\n",
    "    return reg.strip(), ciclo\n",
    "\n",
    "def construir_catalogo(base_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    if not base_dir.exists():\n",
    "        return pd.DataFrame(columns=[\"Region\",\"Ciclo\",\"Ruta\"])\n",
    "    for reg_folder in sorted(os.listdir(base_dir)):\n",
    "        d = base_dir / reg_folder\n",
    "        if not d.is_dir(): continue\n",
    "        for f in sorted(os.listdir(d)):\n",
    "            if not f.lower().endswith(\".csv\"): continue\n",
    "            reg, ciclo = parse_unison_filename(f)\n",
    "            if reg and ciclo:\n",
    "                rows.append({\"Region\": reg, \"Ciclo\": ciclo, \"Ruta\": str(d / f)})\n",
    "    return pd.DataFrame(rows).sort_values([\"Region\",\"Ciclo\"]).reset_index(drop=True)\n",
    "\n",
    "CAT = construir_catalogo(RUTA_SALIDA_UNISON)\n",
    "display(CAT.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fd9b9d-a8f5-4d6e-b536-678d1d3a3a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 3: Capturador de figuras y helpers PDF ===\n",
    "\n",
    "class FiguraCapture:\n",
    "    \"\"\"\n",
    "    Captura TODAS las figuras nuevas creadas por matplotlib mientras se ejecuta el bloque del profesor.\n",
    "    \"\"\"\n",
    "    def __enter__(self):\n",
    "        self._before = set(plt.get_fignums())\n",
    "        return self\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        self.figs = []\n",
    "        after = set(plt.get_fignums())\n",
    "        new_ids = sorted(list(after - self._before))\n",
    "        for fid in new_ids:\n",
    "            fig = plt.figure(fid)\n",
    "            self.figs.append(fig)\n",
    "\n",
    "def add_plotly_fig_as_matplotlib(fig):\n",
    "    \"\"\"\n",
    "    Convierte un fig de Plotly a imagen (PNG) usando kaleido y lo mete en una Figure de matplotlib\n",
    "    para poder guardarlo en el PDF.\n",
    "    \"\"\"\n",
    "    buf = pio.to_image(fig, format=\"png\", scale=2)  # requiere `kaleido`\n",
    "    bio = BytesIO(buf)\n",
    "    img = mpimg.imread(bio, format='png')\n",
    "    mfig = plt.figure(figsize=(12,6))\n",
    "    ax = mfig.add_subplot(111)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    return mfig\n",
    "\n",
    "def pagina_portada(pdf: PdfPages, region: str, ciclos: list):\n",
    "    fig = plt.figure(figsize=(12,7)); plt.axis('off')\n",
    "    titulo = f\"Reporte de Modelos — {region}\"\n",
    "    subt = \"Ciclos incluidos: \" + \", \".join(ciclos)\n",
    "    plt.text(0.5, 0.65, titulo, ha='center', va='center', fontsize=24, weight='bold')\n",
    "    plt.text(0.5, 0.45, subt,   ha='center', va='center', fontsize=12)\n",
    "    plt.text(0.5, 0.15, f\"Generado: {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "             ha='center', va='center', fontsize=10, alpha=0.7)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "def kpis_basicos(df: pd.DataFrame) -> dict:\n",
    "    mask = df[\"ETc\"].notna() if \"ETc\" in df else pd.Series(False, index=df.index)\n",
    "    dias = int(mask.sum())\n",
    "    etc_total = float(df.loc[mask, \"ETc\"].sum())     if \"ETc\"     in df else np.nan\n",
    "    etv_total = float(df.loc[mask, \"ETverde\"].sum()) if \"ETverde\" in df else np.nan\n",
    "    eta_total = float(df.loc[mask, \"ETazul\"].sum())  if \"ETazul\"  in df else np.nan\n",
    "    tmax = float(df[\"Tmax\"].max()) if \"Tmax\" in df else np.nan\n",
    "    tmin = float(df[\"Tmin\"].min()) if \"Tmin\" in df else np.nan\n",
    "    return {\"dias\":dias,\"etc_total\":etc_total,\"etv_total\":etv_total,\"eta_total\":eta_total,\"tmax\":tmax,\"tmin\":tmin}\n",
    "\n",
    "def pagina_kpis(pdf: PdfPages, region: str, ciclo: str, df: pd.DataFrame):\n",
    "    k = kpis_basicos(df)\n",
    "    fig, ax = plt.subplots(figsize=(12,6)); ax.axis('off')\n",
    "    ax.text(0.02, 0.95, f\"{region} — {ciclo}\", fontsize=16, weight='bold')\n",
    "    lines = [\n",
    "        f\"Días del ciclo: {k['dias']}\",\n",
    "        f\"ETc total [mm]: {k['etc_total']:.1f}\" if not np.isnan(k['etc_total']) else \"ETc total: —\",\n",
    "        f\"ETverde total [mm]: {k['etv_total']:.1f}\" if not np.isnan(k['etv_total']) else \"ETverde total: —\",\n",
    "        f\"ETazul total [mm]: {k['eta_total']:.1f}\" if not np.isnan(k['eta_total']) else \"ETazul total: —\",\n",
    "        f\"Tmax / Tmin [°C]: {k['tmax']:.1f} / {k['tmin']:.1f}\" if not np.isnan(k['tmax']) else \"Tmax/Tmin: —\",\n",
    "    ]\n",
    "    for i, L in enumerate(lines):\n",
    "        ax.text(0.05, 0.8 - 0.1*i, L, fontsize=12)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "def anexar_figuras(pdf: PdfPages, figs: list, titulo_encabezado: str = None):\n",
    "    if titulo_encabezado:\n",
    "        fig = plt.figure(figsize=(12,1.2)); plt.axis('off')\n",
    "        plt.text(0.02, 0.5, titulo_encabezado, va='center', fontsize=14, weight='bold')\n",
    "        pdf.savefig(fig); plt.close(fig)\n",
    "    for f in figs:\n",
    "        pdf.savefig(f); plt.close(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b71313c-570e-462b-8ff4-ced1cc776951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Celda 4: BLOQUE DEL PROFESOR (integrado) ===\n",
    "def correr_bloques_profesor(df: pd.DataFrame, region: str, ciclo: str):\n",
    "    \"\"\"\n",
    "    Replicamos la libreta del profesor, usando 'df' ya cargado/normalizado.\n",
    "    Se generan las mismas figuras. Las de Plotly se exportan a imagen para meterlas al PDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    logs = []   # <--- agrega esta línea\n",
    "\n",
    "    # ---------- Correlación ----------\n",
    "    variables = ['Tmax', 'Tmin', 'Tmean', 'HR', 'Ux', 'Rs', 'ET0', 'ETc']\n",
    "    df_selected = df[[v for v in variables if v in df.columns]].dropna()\n",
    "    if not df_selected.empty and df_selected.shape[1] >= 2:\n",
    "        corr_matrix = df_selected.corr()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        mask = np.triu(np.ones_like(corr_matrix))\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='viridis', fmt=\".2f\", square=True, mask=mask)\n",
    "        plt.title(\"Matriz de Correlación entre Variables Meteorológicas\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    # ---------- Dispersión (Tmax, Rs, HR, Ux) vs ET0; ET0 vs ETc ----------\n",
    "    variables_disp = [c for c in ['Tmax','HR','Ux','Rs','ET0','ETc'] if c in df.columns]\n",
    "    if all(c in df.columns for c in ['Tmax','HR','Ux','Rs','ET0']) or 'ETc' in df.columns:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = np.array(axes)\n",
    "        # guardas para no explotar si falta algo\n",
    "        try:\n",
    "            if 'Tmax' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='Tmax', y='ET0', data=df, ax=axes[0, 0], color='blue')\n",
    "                axes[0, 0].set_title('Tmax vs ET0')\n",
    "            if 'Rs' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='Rs', y='ET0', data=df, ax=axes[0, 1], color='green')\n",
    "                axes[0, 1].set_title('Rs vs ET0')\n",
    "            if 'HR' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='HR', y='ET0', data=df, ax=axes[0, 2], color='red')\n",
    "                axes[0, 2].set_title('HR vs ET0')\n",
    "            if 'Ux' in df and 'ET0' in df:\n",
    "                sns.scatterplot(x='Ux', y='ET0', data=df, ax=axes[1, 0], color='purple')\n",
    "                axes[1, 0].set_title('Ux vs ET0')\n",
    "            if 'ET0' in df and 'ETc' in df:\n",
    "                sns.scatterplot(x='ET0', y='ETc', data=df, ax=axes[1, 1], color='orange')\n",
    "                axes[1, 1].set_title('ET0 vs ETc')\n",
    "            # elimina el último si sobra\n",
    "            try:\n",
    "                fig.delaxes(axes[1, 2])\n",
    "            except Exception:\n",
    "                pass\n",
    "            fig.suptitle(f\"Dispersión — {region} ({ciclo})\")\n",
    "            fig.tight_layout()\n",
    "        except Exception:\n",
    "            plt.close(fig)\n",
    "\n",
    "    # ---------- Regresión Lineal para ET0 ----------\n",
    "    features = [c for c in ['Tmax','Tmin','HR','Ux','Rs'] if c in df.columns]\n",
    "    target = 'ET0'\n",
    "    if target in df.columns and len(features) >= 2:\n",
    "        df_model = df[features + [target]].dropna()\n",
    "        if not df_model.empty:\n",
    "            X = df_model[features]\n",
    "            y = df_model[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            #print(f\"[{region} {ciclo}] Regresión Lineal ET0 — R²: {r2:.4f}  MSE: {mse:.4f}\")\n",
    "            \n",
    "            logs.append(f\"[{region} {ciclo}] Regresión Lineal ET0 — R²: {r2:.4f}  MSE: {mse:.4f}\")\n",
    "\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.scatterplot(x=y_test, y=y_pred)\n",
    "            lim_min = min(y_test.min(), y_pred.min())\n",
    "            lim_max = max(y_test.max(), y_pred.max())\n",
    "            plt.plot([lim_min, lim_max], [lim_min, lim_max], 'r--')\n",
    "            plt.xlabel('ET0 Real')\n",
    "            plt.ylabel('ET0 Predicho')\n",
    "            plt.title(f\"Comparación entre ET0 Real y Predicho — {region} ({ciclo})\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "    # ---------- Random Forest para ET0 ----------\n",
    "    if target in df.columns and len(features) >= 2:\n",
    "        df_rf = df[features + [target]].dropna()\n",
    "        if not df_rf.empty:\n",
    "            X = df_rf[features]\n",
    "            y = df_rf[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "            rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "\n",
    "            r2_rf = r2_score(y_test, y_pred)\n",
    "            mse_rf = mean_squared_error(y_test, y_pred)\n",
    "            #print(f\"[{region} {ciclo}] Random Forest ET0 — R²: {r2_rf:.4f}  MSE: {mse_rf:.4f}\")\n",
    "            #print(f\"Importancias: {dict(zip(features, rf.feature_importances_))}\")\n",
    "\n",
    "            logs.append(f\"[{region} {ciclo}] Random Forest ET0 — R²: {r2_rf:.4f}  MSE: {mse_rf:.4f}\")\n",
    "            logs.append(f\"Importancias: {dict(zip(features, rf.feature_importances_))}\")\n",
    "\n",
    "            # Importancias (barras)\n",
    "            imp_series = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "            plt.figure(figsize=(8,4))\n",
    "            imp_series.plot(kind='bar')\n",
    "            plt.title(f\"Importancia de variables (RF) — {region} ({ciclo})\")\n",
    "            plt.ylabel(\"Importancia\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "    # ---------- Agrupamientos (KMeans) con meteo ----------\n",
    "    meteo_cols = [c for c in ['Tmax','Tmin','HR','Ux','Rs'] if c in df.columns]\n",
    "    Xmet = df[meteo_cols].dropna() if meteo_cols else pd.DataFrame()\n",
    "    if not Xmet.empty and Xmet.shape[1] >= 2:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(Xmet)\n",
    "\n",
    "        # método del codo\n",
    "        inertia = []\n",
    "        ks = list(range(2, 10))\n",
    "        for k in ks:\n",
    "            km = KMeans(n_clusters=k, random_state=42)\n",
    "            km.fit(X_scaled)\n",
    "            inertia.append(km.inertia_)\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.plot(ks, inertia, marker='o')\n",
    "        plt.title(\"Método del codo\")\n",
    "        plt.xlabel(\"Número de clústeres\")\n",
    "        plt.ylabel(\"Inercia\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        k_final = 5\n",
    "        km = KMeans(n_clusters=k_final, random_state=42)\n",
    "        df['Grupo'] = km.fit_predict(X_scaled)\n",
    "\n",
    "        if 'Tmax' in df and 'Rs' in df and 'Grupo' in df:\n",
    "            plt.figure(figsize=(7,5))\n",
    "            sns.scatterplot(data=df, x='Tmax', y='Rs', hue='Grupo', palette='Set2')\n",
    "            plt.title(f\"Clasificación de días climáticos — {region} ({ciclo})\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "        # Días por grupo\n",
    "        if 'Día' in df and 'Grupo' in df:\n",
    "            # pares (grupo, día)\n",
    "            dias_por_grupo = { k: df[df['Grupo'] == k]['Día'].dropna().astype(int).tolist()\n",
    "                               for k in sorted(df['Grupo'].dropna().unique()) }\n",
    "            filas = [(g, d) for g, dias in dias_por_grupo.items() for d in dias]\n",
    "            df_dias = pd.DataFrame(filas, columns=['Grupo','Día'])\n",
    "            df['grupo_index'] = df.groupby('Grupo').cumcount()\n",
    "            df_dias['grupo_index'] = df_dias.groupby('Grupo').cumcount()\n",
    "            df_grupos = df.merge(df_dias, on=['Grupo','grupo_index'], how='left').drop(columns=['grupo_index'])\n",
    "\n",
    "            # scatter Día vs Grupo\n",
    "            plot_df_grupos = df_grupos[['Día_y','Grupo']].dropna()\n",
    "            if not plot_df_grupos.empty:\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                sns.scatterplot(data=plot_df_grupos, x='Día_y', y='Grupo', hue='Grupo', palette='Set2')\n",
    "                plt.title(f'Distribución de días por grupo — {region} ({ciclo})')\n",
    "                plt.xlabel('Día del año'); plt.ylabel('Grupo')\n",
    "                plt.tight_layout()\n",
    "\n",
    "            # ---------- Boxplots con Plotly por década/variable/Grupo ----------\n",
    "            # Si existen columnas necesarias:\n",
    "            if 'decada' in df_grupos.columns:\n",
    "                # variables para box (usa meteo_cols si existen)\n",
    "                for var in meteo_cols:\n",
    "                    try:\n",
    "                        figpx = px.box(\n",
    "                            df_grupos.dropna(subset=['decada', var, 'Grupo']),\n",
    "                            x='decada', y=var, color='Grupo',\n",
    "                            title=f'{var} por grupo y década — {region} ({ciclo})',\n",
    "                            labels={'decada':'Década', var:var, 'Grupo':'Grupo'},\n",
    "                            color_discrete_sequence=px.colors.qualitative.Set2,\n",
    "                            points='all'\n",
    "                        )\n",
    "                        figpx.update_layout(boxmode='group', legend_title='Grupo', template='plotly_white')\n",
    "                        # exportar a imagen y agregar al PDF\n",
    "                        mfig = add_plotly_fig_as_matplotlib(figpx)\n",
    "                        plt.close(mfig)\n",
    "                        # NOTA: no se añade aquí; el capturador solo recoge matplotlib generadas en esta función.\n",
    "                        # Para asegurarnos de que entren al PDF, mostramos la figura matplotlib creada:\n",
    "                        mfig = add_plotly_fig_as_matplotlib(figpx)\n",
    "                        plt.show()  # se registra en la lista de matplotlib\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    # ---------- Clusters agregando ET0 y ETc ----------\n",
    "    vars2 = [c for c in ['Tmax','Tmin','HR','Ux','Rs','ET0','ETc'] if c in df.columns]\n",
    "    if len(vars2) >= 3:\n",
    "        df1 = df.copy()\n",
    "        data = df1[vars2].dropna()\n",
    "        if not data.empty:\n",
    "            scaler = StandardScaler()\n",
    "            data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "            kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "            df1['cluster'] = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "            # estadísticas descriptivas (solo imprime)\n",
    "            stats = df1.groupby('cluster')[vars2].agg(['mean'])\n",
    "            #print(\"Estadísticas descriptivas por grupo:\")\n",
    "            #print(stats)\n",
    "\n",
    "            logs.append(\"Estadísticas descriptivas por grupo (medias):\")\n",
    "            logs.append(stats.to_string())\n",
    "            \n",
    "            # boxplots (seaborn) por variable\n",
    "            n = len(vars2)\n",
    "            nrows = int(np.ceil((n)/2))\n",
    "            ncols = 2\n",
    "            fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 4*nrows))\n",
    "            axes = np.array(axes).reshape(nrows, ncols)\n",
    "            idx = 0\n",
    "            for r in range(nrows):\n",
    "                for c in range(ncols):\n",
    "                    if idx < n:\n",
    "                        var = vars2[idx]\n",
    "                        sns.boxplot(x='cluster', y=var, data=df1, ax=axes[r, c], palette='Set1')\n",
    "                        axes[r, c].set_title(f'Distribución de {var} por grupo', fontsize=12)\n",
    "                        axes[r, c].set_xlabel('Grupo'); axes[r, c].set_ylabel(var)\n",
    "                        idx += 1\n",
    "                    else:\n",
    "                        axes[r, c].set_visible(False)\n",
    "            fig.suptitle(f\"Boxplots por grupo — {region} ({ciclo})\")\n",
    "            fig.tight_layout()\n",
    "\n",
    "            # otro KMeans a 5 clústeres (como en la libreta)\n",
    "            k_final = 5\n",
    "            km = KMeans(n_clusters=k_final, random_state=42)\n",
    "            df1['Grupo'] = km.fit_predict(data_scaled)\n",
    "\n",
    "            if 'Tmax' in df1 and 'Rs' in df1:\n",
    "                plt.figure(figsize=(7,5))\n",
    "                sns.scatterplot(data=df1, x='Tmax', y='Rs', hue='Grupo', palette='Set1')\n",
    "                plt.title(f\"Clasificación de días climáticos (ET0/ETc incluidos) — {region} ({ciclo})\")\n",
    "                plt.tight_layout()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a96aa4-467c-4887-be99-125688f009c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Generando PDF para Cajeme: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Cajeme_model_report.pdf\n",
      "   ▸ Procesando Cajeme — 2010-2011\n",
      "   ▸ Procesando Cajeme — 2011-2012\n",
      "   ▸ Procesando Cajeme — 2012-2013\n",
      "   ▸ Procesando Cajeme — 2013-2014\n",
      "   ▸ Procesando Cajeme — 2014-2015\n",
      "   ▸ Procesando Cajeme — 2015-2016\n",
      "   ▸ Procesando Cajeme — 2016-2017\n",
      "   ▸ Procesando Cajeme — 2017-2018\n",
      "   ▸ Procesando Cajeme — 2018-2019\n",
      "   ▸ Procesando Cajeme — 2019-2020\n",
      "   ▸ Procesando Cajeme — 2020-2021\n",
      "   ▸ Procesando Cajeme — 2021-2022\n",
      "   ▸ Procesando Cajeme — 2022-2023\n",
      "   ▸ Procesando Cajeme — 2023-2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Cajeme_model_report.pdf\n",
      "\n",
      "🧾 Generando PDF para Ensenada: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Ensenada_model_report.pdf\n",
      "   ▸ Procesando Ensenada — 2010-2011\n",
      "   ▸ Procesando Ensenada — 2011-2012\n",
      "   ▸ Procesando Ensenada — 2012-2013\n",
      "   ▸ Procesando Ensenada — 2013-2014\n",
      "   ▸ Procesando Ensenada — 2014-2015\n",
      "   ▸ Procesando Ensenada — 2015-2016\n",
      "   ▸ Procesando Ensenada — 2016-2017\n",
      "   ▸ Procesando Ensenada — 2017-2018\n",
      "   ▸ Procesando Ensenada — 2018-2019\n",
      "   ▸ Procesando Ensenada — 2019-2020\n",
      "   ▸ Procesando Ensenada — 2020-2021\n",
      "   ▸ Procesando Ensenada — 2021-2022\n",
      "   ▸ Procesando Ensenada — 2022-2023\n",
      "   ▸ Procesando Ensenada — 2023-2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Ensenada_model_report.pdf\n",
      "\n",
      "🧾 Generando PDF para Etchojoa: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Etchojoa_model_report.pdf\n",
      "   ▸ Procesando Etchojoa — 2010-2011\n",
      "   ▸ Procesando Etchojoa — 2011-2012\n",
      "   ▸ Procesando Etchojoa — 2012-2013\n",
      "   ▸ Procesando Etchojoa — 2013-2014\n",
      "   ▸ Procesando Etchojoa — 2014-2015\n",
      "   ▸ Procesando Etchojoa — 2015-2016\n",
      "   ▸ Procesando Etchojoa — 2016-2017\n",
      "   ▸ Procesando Etchojoa — 2017-2018\n",
      "   ▸ Procesando Etchojoa — 2018-2019\n",
      "   ▸ Procesando Etchojoa — 2019-2020\n",
      "   ▸ Procesando Etchojoa — 2020-2021\n",
      "   ▸ Procesando Etchojoa — 2021-2022\n",
      "   ▸ Procesando Etchojoa — 2022-2023\n",
      "   ▸ Procesando Etchojoa — 2023-2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Etchojoa_model_report.pdf\n",
      "\n",
      "🧾 Generando PDF para Metepec: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Metepec_model_report.pdf\n",
      "   ▸ Procesando Metepec — 2010\n",
      "   ▸ Procesando Metepec — 2011\n",
      "   ▸ Procesando Metepec — 2012\n",
      "   ▸ Procesando Metepec — 2013\n",
      "   ▸ Procesando Metepec — 2014\n",
      "   ▸ Procesando Metepec — 2015\n",
      "   ▸ Procesando Metepec — 2016\n",
      "   ▸ Procesando Metepec — 2017\n",
      "   ▸ Procesando Metepec — 2018\n",
      "   ▸ Procesando Metepec — 2019\n",
      "   ▸ Procesando Metepec — 2020\n",
      "   ▸ Procesando Metepec — 2021\n",
      "   ▸ Procesando Metepec — 2022\n",
      "   ▸ Procesando Metepec — 2023\n",
      "   ▸ Procesando Metepec — 2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Metepec_model_report.pdf\n",
      "\n",
      "🧾 Generando PDF para Toluca: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Toluca_model_report.pdf\n",
      "   ▸ Procesando Toluca — 2010\n",
      "   ▸ Procesando Toluca — 2011\n",
      "   ▸ Procesando Toluca — 2012\n",
      "   ▸ Procesando Toluca — 2013\n",
      "   ▸ Procesando Toluca — 2014\n",
      "   ▸ Procesando Toluca — 2015\n",
      "   ▸ Procesando Toluca — 2016\n",
      "   ▸ Procesando Toluca — 2017\n",
      "   ▸ Procesando Toluca — 2018\n",
      "   ▸ Procesando Toluca — 2019\n",
      "   ▸ Procesando Toluca — 2020\n",
      "   ▸ Procesando Toluca — 2021\n",
      "   ▸ Procesando Toluca — 2022\n",
      "   ▸ Procesando Toluca — 2023\n",
      "   ▸ Procesando Toluca — 2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Toluca_model_report.pdf\n",
      "\n",
      "🧾 Generando PDF para Villa de Allende: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Villa_de_Allende_model_report.pdf\n",
      "   ▸ Procesando Villa de Allende — 2010\n",
      "   ▸ Procesando Villa de Allende — 2011\n",
      "   ▸ Procesando Villa de Allende — 2012\n",
      "   ▸ Procesando Villa de Allende — 2013\n",
      "   ▸ Procesando Villa de Allende — 2014\n",
      "   ▸ Procesando Villa de Allende — 2015\n",
      "   ▸ Procesando Villa de Allende — 2016\n",
      "   ▸ Procesando Villa de Allende — 2017\n",
      "   ▸ Procesando Villa de Allende — 2018\n",
      "   ▸ Procesando Villa de Allende — 2019\n",
      "   ▸ Procesando Villa de Allende — 2020\n",
      "   ▸ Procesando Villa de Allende — 2021\n",
      "   ▸ Procesando Villa de Allende — 2022\n",
      "   ▸ Procesando Villa de Allende — 2023\n",
      "   ▸ Procesando Villa de Allende — 2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Villa_de_Allende_model_report.pdf\n",
      "\n",
      "🧾 Generando PDF para Zapopan: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Zapopan_model_report.pdf\n",
      "   ▸ Procesando Zapopan — 2010\n",
      "   ▸ Procesando Zapopan — 2011\n",
      "   ▸ Procesando Zapopan — 2012\n",
      "   ▸ Procesando Zapopan — 2013\n",
      "   ▸ Procesando Zapopan — 2014\n",
      "   ▸ Procesando Zapopan — 2015\n",
      "   ▸ Procesando Zapopan — 2016\n",
      "   ▸ Procesando Zapopan — 2017\n",
      "   ▸ Procesando Zapopan — 2018\n",
      "   ▸ Procesando Zapopan — 2019\n",
      "   ▸ Procesando Zapopan — 2020\n",
      "   ▸ Procesando Zapopan — 2021\n",
      "   ▸ Procesando Zapopan — 2022\n",
      "   ▸ Procesando Zapopan — 2023\n",
      "   ▸ Procesando Zapopan — 2024\n",
      "✅ PDF guardado: /lustre/home/mvalenzuela/Workspace/DataAqua-dashboard/reports/modelos/Zapopan_model_report.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Celda 5: Proceso por lote (PDF por región con TODAS las figuras del profesor) ===\n",
    "\n",
    "CAT = construir_catalogo(RUTA_SALIDA_UNISON)\n",
    "if CAT.empty:\n",
    "    raise SystemExit(\"No se encontraron archivos en la ruta de datos.\")\n",
    "\n",
    "regiones = sorted(CAT[\"Region\"].unique())\n",
    "for region in regiones:\n",
    "    cat_reg = CAT[CAT[\"Region\"] == region].sort_values(\"Ciclo\")\n",
    "    ciclos = list(cat_reg[\"Ciclo\"].unique())\n",
    "    salida_pdf = RUTA_REPORTES / f\"{region.replace(' ', '_')}_model_report.pdf\"\n",
    "    print(f\"🧾 Generando PDF para {region}: {salida_pdf}\")\n",
    "\n",
    "    with PdfPages(salida_pdf) as pdf:\n",
    "        # Portada\n",
    "        pagina_portada(pdf, region, ciclos)\n",
    "\n",
    "        # Por cada ciclo\n",
    "        for ciclo, ruta in cat_reg[[\"Ciclo\",\"Ruta\"]].itertuples(index=False):\n",
    "            print(f\"   ▸ Procesando {region} — {ciclo}\")\n",
    "            df = leer_y_normalizar(ruta)\n",
    "            if df.empty:\n",
    "                print(\"     (sin datos, se omite)\"); continue\n",
    "\n",
    "            # KPI básicos (siempre)\n",
    "            pagina_kpis(pdf, region, ciclo, df)\n",
    "\n",
    "            # Captura TODAS las figuras matplotlib que genere el bloque del profesor\n",
    "            # with FiguraCapture() as cap:\n",
    "            #     correr_bloques_profesor(df, region, ciclo)\n",
    "\n",
    "            # # Agrega todas las figuras capturadas\n",
    "            # if getattr(cap, \"figs\", None):\n",
    "            #     anexar_figuras(pdf, cap.figs, titulo_encabezado=f\"{region} — {ciclo}\")\n",
    "\n",
    "            with FiguraCapture() as cap:\n",
    "                logs = correr_bloques_profesor(df, region, ciclo)\n",
    "\n",
    "            # 1) Página de métricos/texto (si hay)\n",
    "            if logs:\n",
    "                texto = \"\\n\".join(logs)\n",
    "                fig_txt, ax_txt = plt.subplots(figsize=(12, 7))\n",
    "                ax_txt.axis('off')\n",
    "                ax_txt.text(0.02, 0.98, f\"{region} — {ciclo}  ·  Resultados y métricas\", fontsize=14, weight='bold', va='top')\n",
    "                ax_txt.text(0.02, 0.92, texto, fontsize=10, va='top', family='monospace', wrap=True)\n",
    "                pdf.savefig(fig_txt); plt.close(fig_txt)\n",
    "\n",
    "            # 2) Todas las figuras capturadas\n",
    "            if getattr(cap, \"figs\", None):\n",
    "                anexar_figuras(pdf, cap.figs, titulo_encabezado=f\"{region} — {ciclo}\")\n",
    "\n",
    "            \n",
    "\n",
    "    print(f\"✅ PDF guardado: {salida_pdf}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efed04f7-d2bf-48c6-89bb-1dccda69fa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beff663-bdef-4cac-8256-670684ce2b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Proyect-Env)",
   "language": "python",
   "name": "proyect-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
